{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import backbone\n",
    "from methods.baselinetrain import BaselineTrain\n",
    "from io_utils import parse_args, get_resume_file, get_best_file, get_assigned_file\n",
    "from datasets import miniImageNet_few_shot, ISIC_few_shot, EuroSAT_few_shot, CropDisease_few_shot, Chest_few_shot\n",
    "from data.datamgr import SimpleDataManager, SetDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustering_measure(features, target, n_way):\n",
    "    N = target.size(0)\n",
    "    C = n_way\n",
    "    \n",
    "    class_features = []\n",
    "    for c in range(5):\n",
    "        class_features.append(features[target==c])\n",
    "    \n",
    "    mu = torch.mean(features, dim=0)\n",
    "    class_mu = []\n",
    "    for c in range(5):\n",
    "        class_mu.append(torch.mean(class_features[c], dim=0))\n",
    "    \n",
    "    sigma_within = 0\n",
    "    sigma_btw = 0\n",
    "    \n",
    "    for c in range(5):\n",
    "        sigma_btw += torch.norm(class_mu[c]-mu)\n",
    "        for feature in class_features[c]:\n",
    "            sigma_within += torch.norm(feature-class_mu[c])\n",
    "    \n",
    "    sigma_within /= N\n",
    "    sigma_btw /= C\n",
    "    \n",
    "    return sigma_within.item(), sigma_btw.item(), (sigma_within/sigma_btw).item()\n",
    "\n",
    "def get_cos(out, y):\n",
    "    cos = torch.nn.CosineSimilarity()\n",
    "    cos_mtx = torch.zeros([len(out), len(out)])\n",
    "    for i in range(len(out)):\n",
    "        cos_mtx[i] = cos(out, out[i].view(1, -1))\n",
    "        \n",
    "    same_mtx = (y.view(1, -1) == y.view(-1, 1)).float().cpu()\n",
    "    diff_mtx = 1 - same_mtx\n",
    "    same_mtx[range(len(same_mtx)), range(len(same_mtx))] = 0.\n",
    "    \n",
    "    same_cos = cos_mtx * same_mtx\n",
    "    diff_cos = cos_mtx * diff_mtx\n",
    "    \n",
    "    return torch.sum(same_cos).item() / len(torch.where(same_cos!=0)[0]), torch.sum(diff_cos).item() / len(torch.where(diff_cos!=0)[0])\n",
    "\n",
    "def get_pretrained_model(model, method, pretrained_dataset, save_dir, track_bn):\n",
    "    if pretrained_dataset == 'miniImageNet':\n",
    "        num_classes = 64\n",
    "    elif pretrained_dataset == 'tieredImageNet':\n",
    "        num_classes = 351\n",
    "    \n",
    "    model_dict = {model: backbone.ResNet10(method=method, track_bn=track_bn, reinit_bn_stats=False)}\n",
    "    pretrained_model = BaselineTrain(model_dict[model], num_classes, loss_type='softmax')\n",
    "    \n",
    "    if track_bn:\n",
    "        checkpoint_dir = '%s/checkpoints/%s/%s_%s_aug_track' %(save_dir, pretrained_dataset, model, method)\n",
    "    else:\n",
    "        checkpoint_dir = '%s/checkpoints/%s/%s_%s_aug' %(save_dir, pretrained_dataset, model, method)\n",
    "        \n",
    "    modelfile = get_resume_file(checkpoint_dir)\n",
    "    state = torch.load(modelfile)['state']\n",
    "\n",
    "    pretrained_model.load_state_dict(state, strict=True)\n",
    "    pretrained_model.cuda()\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    for p in pretrained_model.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "iter_num = 100\n",
    "\n",
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 15\n",
    "few_shot_params = dict(n_way=n_way, n_support=n_support)\n",
    "\n",
    "dataset_names = [\"miniImageNet\", \"miniImageNet_test\", \"CropDisease\", \"EuroSAT\", \"ISIC\", \"ChestX\"]\n",
    "method = 'baseline'\n",
    "model = 'ResNet10'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print (dataset_name)\n",
    "    if dataset_name == \"miniImageNet\" or dataset_name == \"miniImageNet_test\":\n",
    "        datamgr = miniImageNet_few_shot.SetDataManager(image_size, n_episode=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"CropDisease\":\n",
    "        datamgr = CropDisease_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"EuroSAT\":\n",
    "        datamgr = EuroSAT_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ISIC\":\n",
    "        datamgr = ISIC_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ChestX\":\n",
    "        datamgr = Chest_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "        \n",
    "    if dataset_name == \"miniImageNet_test\":\n",
    "        novel_loader = datamgr.get_data_loader(aug=False, train=False)\n",
    "    else:\n",
    "        novel_loader = datamgr.get_data_loader(aug=False)\n",
    "\n",
    "    clustering_measure_mtx = np.zeros([len(novel_loader), 4])\n",
    "    \n",
    "    for task_num, (x, y) in tqdm(enumerate(novel_loader)):\n",
    "        n_query = x.size(1) - n_support\n",
    "        x = x.cuda()\n",
    "        x_var = Variable(x)\n",
    "\n",
    "        x_a_i = x_var[:,:n_support,:,:,:].contiguous().view( n_way* n_support, *x.size()[2:]) # (25 (5-way * 5-n_support), 3, 224, 224)\n",
    "        # x_b_i = x_var[:,n_support:,:,:,:].contiguous().view( n_way* n_query, *x.size()[2:]) # (75 (5-way * 15-n_qeury), 3, 224, 224)\n",
    "        y_a_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_support ) )).cuda() # (25,)\n",
    "        # y_b_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_query ) )).cuda() # (75,)\n",
    "\n",
    "        pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir, track_bn=True)\n",
    "        block1_out, block2_out, block3_out, block4_out = pretrained_model.feature.return_features(x_a_i)\n",
    "        y = y_a_i\n",
    "        \n",
    "#         intra_cos = []\n",
    "#         inter_cos = []\n",
    "        \n",
    "        for k, out in enumerate([block1_out, block2_out, block3_out, block4_out]):\n",
    "            _, _, c = get_clustering_measure(out, y, n_way)\n",
    "#             intra, inter = get_cos(out, y)\n",
    "#             intra_cos.append(intra)\n",
    "#             inter_cos.append(inter)\n",
    "            clustering_measure_mtx[task_num, k] = c\n",
    "        \n",
    "#         xrange = ['block1', 'block2', 'block3', 'block4', 'last (avgpool)']\n",
    "#         plt.title('dataset: {}, method: {}'.format(dataset_name, method))\n",
    "#         plt.plot(xrange, intra_cos, ls='-', marker='o', color='b', label='intra_cos')\n",
    "#         plt.plot(xrange, inter_cos, ls='-', marker='o', color='r', label='inter_cos')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "\n",
    "    xrange = ['block1', 'block2', 'block3', 'block4']\n",
    "    plt.errorbar(xrange, np.mean(clustering_measure_mtx, axis=0), yerr=np.std(clustering_measure_mtx, axis=0), fmt='-o', capsize=5)\n",
    "#     plt.plot(xrange, baseline_clustering, ls='-', marker='o', label=dataset_name)\n",
    "    \n",
    "    plt.title('{} clustering measure'.format(method))\n",
    "#     plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "iter_num = 100\n",
    "\n",
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 15\n",
    "few_shot_params = dict(n_way=n_way, n_support=n_support)\n",
    "\n",
    "dataset_names = [\"miniImageNet\", \"miniImageNet_test\", \"CropDisease\", \"EuroSAT\", \"ISIC\", \"ChestX\"]\n",
    "method = 'baseline'\n",
    "model = 'ResNet10'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print (dataset_name)\n",
    "    if dataset_name == \"miniImageNet\" or dataset_name == \"miniImageNet_test\":\n",
    "        datamgr = miniImageNet_few_shot.SetDataManager(image_size, n_episode=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"CropDisease\":\n",
    "        datamgr = CropDisease_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"EuroSAT\":\n",
    "        datamgr = EuroSAT_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ISIC\":\n",
    "        datamgr = ISIC_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ChestX\":\n",
    "        datamgr = Chest_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "        \n",
    "    if dataset_name == \"miniImageNet_test\":\n",
    "        novel_loader = datamgr.get_data_loader(aug=False, train=False)\n",
    "    else:\n",
    "        novel_loader = datamgr.get_data_loader(aug=False)\n",
    "\n",
    "    clustering_measure_mtx = np.zeros([len(novel_loader), 4])\n",
    "    \n",
    "    for task_num, (x, y) in tqdm(enumerate(novel_loader)):\n",
    "        n_query = x.size(1) - n_support\n",
    "        x = x.cuda()\n",
    "        x_var = Variable(x)\n",
    "\n",
    "        x_a_i = x_var[:,:n_support,:,:,:].contiguous().view( n_way* n_support, *x.size()[2:]) # (25 (5-way * 5-n_support), 3, 224, 224)\n",
    "        # x_b_i = x_var[:,n_support:,:,:,:].contiguous().view( n_way* n_query, *x.size()[2:]) # (75 (5-way * 15-n_qeury), 3, 224, 224)\n",
    "        y_a_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_support ) )).cuda() # (25,)\n",
    "        # y_b_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_query ) )).cuda() # (75,)\n",
    "\n",
    "        pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir, track_bn=False)\n",
    "        block1_out, block2_out, block3_out, block4_out = pretrained_model.feature.return_features(x_a_i)\n",
    "        y = y_a_i\n",
    "        \n",
    "#         intra_cos = []\n",
    "#         inter_cos = []\n",
    "        \n",
    "        for k, out in enumerate([block1_out, block2_out, block3_out, block4_out]):\n",
    "            _, _, c = get_clustering_measure(out, y, n_way)\n",
    "#             intra, inter = get_cos(out, y)\n",
    "#             intra_cos.append(intra)\n",
    "#             inter_cos.append(inter)\n",
    "            clustering_measure_mtx[task_num, k] = c\n",
    "        \n",
    "#         xrange = ['block1', 'block2', 'block3', 'block4', 'last (avgpool)']\n",
    "#         plt.title('dataset: {}, method: {}'.format(dataset_name, method))\n",
    "#         plt.plot(xrange, intra_cos, ls='-', marker='o', color='b', label='intra_cos')\n",
    "#         plt.plot(xrange, inter_cos, ls='-', marker='o', color='r', label='inter_cos')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "\n",
    "    xrange = ['block1', 'block2', 'block3', 'block4']\n",
    "    plt.errorbar(xrange, np.mean(clustering_measure_mtx, axis=0), yerr=np.std(clustering_measure_mtx, axis=0), fmt='-o', capsize=5)\n",
    "#     plt.plot(xrange, baseline_clustering, ls='-', marker='o', label=dataset_name)\n",
    "    \n",
    "    plt.title('{} clustering measure'.format(method))\n",
    "#     plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamgr = miniImageNet_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "base_loader = datamgr.get_data_loader(aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'ResNet10'\n",
    "method = 'baseline'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img_t):\n",
    "    norm_dict = dict(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225]))\n",
    "    tf = transforms.ToPILImage()\n",
    "    \n",
    "    img = img_t.cpu() * norm_dict['std'].view(-1, 1, 1) + norm_dict['mean'].view(-1, 1, 1)\n",
    "    \n",
    "    return tf(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label) in enumerate(base_loader):\n",
    "    image = image.cuda()\n",
    "    block1_out, block2_out, block3_out, block4_out, last_out = pretrained_model.feature.return_features(image)\n",
    "    \n",
    "    if idx == 0:\n",
    "        repr_all = last_out.cpu()\n",
    "        # image_all = image.cpu()\n",
    "        label_all = label\n",
    "    else:\n",
    "        repr_all = torch.cat([repr_all, last_out.cpu()], dim=0)\n",
    "        # image_all = torch.cat([image_all, image.cpu()], dim=0)\n",
    "        label_all = torch.cat([label_all, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lab in enumerate([0, 1, 2, 3, 4]):\n",
    "    find_idx = torch.where(label_all==lab)[0]\n",
    "    if i == 0:\n",
    "        repr_selected = repr_all[find_idx]\n",
    "        # image_selected = image_all[find_idx]\n",
    "        label_selected = label_all[find_idx]\n",
    "    else:\n",
    "        repr_selected = torch.cat([repr_selected, repr_all[find_idx]])\n",
    "        # image_selected = torch.cat([image_selected, image_all[find_idx]])\n",
    "        label_selected = torch.cat([label_selected, label_all[find_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  tsne_torch.py\n",
    "#\n",
    "# Implementation of t-SNE in pytorch. The implementation was tested on pytorch\n",
    "# > 1.0, and it requires Numpy to read files. In order to plot the results,\n",
    "# a working installation of matplotlib is required.\n",
    "#\n",
    "#\n",
    "# The example can be run by executing: `python tsne_torch.py`\n",
    "#\n",
    "#\n",
    "#  Created by Xiao Li on 23-03-2020.\n",
    "#  Copyright (c) 2020. All rights reserved.\n",
    "\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "def Hbeta_torch(D, beta=1.0):\n",
    "    P = torch.exp(-D.clone() * beta)\n",
    "\n",
    "    sumP = torch.sum(P)\n",
    "\n",
    "    H = torch.log(sumP) + beta * torch.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "\n",
    "    return H, P\n",
    "\n",
    "\n",
    "def x2p_torch(X, tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "\n",
    "    sum_X = torch.sum(X*X, 1)\n",
    "    D = torch.add(torch.add(-2 * torch.mm(X, X.t()), sum_X).t(), sum_X)\n",
    "\n",
    "    P = torch.zeros(n, n)\n",
    "    beta = torch.ones(n, 1)\n",
    "    logU = torch.log(torch.tensor([perplexity]))\n",
    "    n_list = [i for i in range(n)]\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        # there may be something wrong with this setting None\n",
    "        betamin = None\n",
    "        betamax = None\n",
    "        Di = D[i, n_list[0:i]+n_list[i+1:n]]\n",
    "\n",
    "        (H, thisP) = Hbeta_torch(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while torch.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].clone()\n",
    "                if betamax is None:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].clone()\n",
    "                if betamin is None:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta_torch(Di, beta[i])\n",
    "\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, n_list[0:i]+n_list[i+1:n]] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    return P\n",
    "\n",
    "\n",
    "def pca_torch(X, no_dims=50):\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - torch.mean(X, 0)\n",
    "\n",
    "    (l, M) = torch.eig(torch.mm(X.t(), X), True)\n",
    "    # split M real\n",
    "    for i in range(d):\n",
    "        if l[i, 1] != 0:\n",
    "            M[:, i+1] = M[:, i]\n",
    "            i += 1\n",
    "\n",
    "    Y = torch.mm(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "\n",
    "\n",
    "def tsne(X, no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should not have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca_torch(X, initial_dims)\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 1000\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = torch.randn(n, no_dims).cuda()\n",
    "    dY = torch.zeros(n, no_dims).cuda()\n",
    "    iY = torch.zeros(n, no_dims).cuda()\n",
    "    gains = torch.ones(n, no_dims).cuda()\n",
    "    \n",
    "    # Compute P-values\n",
    "    P = x2p_torch(X, 1e-5, perplexity)\n",
    "    P = P + P.t()\n",
    "    P = P / torch.sum(P)\n",
    "    P = P * 4.    # early exaggeration\n",
    "    print(\"get P shape\", P.shape)\n",
    "    P = torch.max(P.cuda(), torch.tensor([1e-21]).cuda())\n",
    "    \n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = torch.sum(Y*Y, 1)\n",
    "        num = -2. * torch.mm(Y, Y.t())\n",
    "        num = 1. / (1. + torch.add(torch.add(num, sum_Y).t(), sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / torch.sum(num)\n",
    "        Q = torch.max(Q, torch.tensor([1e-12]).cuda())\n",
    "        \n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = torch.sum((PQ[:, i] * num[:, i]).repeat(no_dims, 1).t() * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)).double() + (gains * 0.8) * ((dY > 0.) == (iY > 0.)).double()\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - torch.mean(Y, 0)\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = torch.sum(P * torch.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = repr_selected\n",
    "labels = label_selected.tolist()\n",
    "\n",
    "# confirm that x file get same number point than label file\n",
    "# otherwise may cause error in scatter\n",
    "assert(len(X[:, 0])==len(X[:,1]))\n",
    "assert(len(X)==len(labels))\n",
    "\n",
    "with torch.no_grad():\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "\n",
    "# You may write result in two files\n",
    "# print(\"Save Y values in file\")\n",
    "# Y1 = open(\"y1.txt\", 'w')\n",
    "# Y2 = open('y2.txt', 'w')\n",
    "# for i in range(Y.shape[0]):\n",
    "#     Y1.write(str(Y[i,0])+\"\\n\")\n",
    "#     Y2.write(str(Y[i,1])+\"\\n\")\n",
    "Y = Y.cpu().numpy()\n",
    "# plt.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "plt.scatter(Y[0:600, 0],     Y[0:600, 1],     20, label='0')\n",
    "plt.scatter(Y[600:1200, 0],  Y[600:1200, 1],  20, label='1')\n",
    "plt.scatter(Y[1200:1800, 0], Y[1200:1800, 1], 20, label='2')\n",
    "plt.scatter(Y[1800:2400, 0], Y[1800:2400, 1], 20, label='3')\n",
    "plt.scatter(Y[2400:3000, 0], Y[2400:3000, 1], 20, label='4')\n",
    "\n",
    "plt.title('method: {}'.format(method))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_selected[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = repr_selected[2].cuda()\n",
    "\n",
    "block1_out, block2_out, block3_out, block4_out, last_out = pretrained_model.feature.return_features(sample.view(1, *sample.shape))\n",
    "plot_img(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "iter_num = 600\n",
    "\n",
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 15\n",
    "few_shot_params = dict(n_way=n_way, n_support=n_support)\n",
    "\n",
    "dataset_names = [\"miniImageNet_test\", \"CropDisease\", \"EuroSAT\", \"ISIC\", \"ChestX\"]\n",
    "method = 'baseline'\n",
    "model = 'ResNet10'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "freeze_backbone = False\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print (dataset_name)\n",
    "    if dataset_name == \"miniImageNet\" or dataset_name == \"miniImageNet_test\":\n",
    "        datamgr = miniImageNet_few_shot.SetDataManager(image_size, n_episode=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"CropDisease\":\n",
    "        datamgr = CropDisease_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"EuroSAT\":\n",
    "        datamgr = EuroSAT_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ISIC\":\n",
    "        datamgr = ISIC_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "    elif dataset_name == \"ChestX\":\n",
    "        datamgr = Chest_few_shot.SetDataManager(image_size, n_eposide=iter_num, n_query=n_query, **few_shot_params)\n",
    "        \n",
    "    if dataset_name == \"miniImageNet_test\":\n",
    "        novel_loader = datamgr.get_data_loader(aug=False, train=False)\n",
    "    else:\n",
    "        novel_loader = datamgr.get_data_loader(aug=False)\n",
    "    \n",
    "    prt_w = []\n",
    "    prt_wo = []\n",
    "    ft_w = []\n",
    "    ft_wo = []\n",
    "    df = pd.DataFrame(np.zeros([iter_num, 5]), columns=['r1.0', 'r0.8', 'r0.5', 'r0.2', 'r0.0'])\n",
    "    \n",
    "    for r in [1.0, 0.8, 0.5, 0.2, 0.0]:\n",
    "        acc_lst = []\n",
    "        for task_num, (x, y) in tqdm(enumerate(novel_loader)):\n",
    "            pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir)\n",
    "\n",
    "            ####################################################################################\n",
    "\n",
    "            if freeze_backbone is False:\n",
    "                for name, p in pretrained_model.named_parameters():\n",
    "                    if 'trunk.7' in name:\n",
    "                        if 'BN' in name:\n",
    "                            pass\n",
    "#                             if 'weight' in name:\n",
    "#                                 p.data.fill_(1.)\n",
    "#                             else:\n",
    "#                                 p.data.fill_(0.)\n",
    "                        else:\n",
    "                            # ber = torch.bernoulli(torch.ones(p.data.shape)*r).cuda()\n",
    "                            # p.data = p.data * ber\n",
    "                            if r == 1.0:\n",
    "                                pass\n",
    "                            elif r == 0.0:\n",
    "                                p.data.fill_(0.)\n",
    "                                # nn.init.kaiming_uniform_(p.data, a=math.sqrt(5))\n",
    "                            else:\n",
    "                                r_dim = int(p.data.shape[0] * r)\n",
    "                                p.data[r_dim:,:,:,:].fill_(0.)\n",
    "                                # nn.init.kaiming_uniform_(p.data[r_dim:,:,:,:], a=math.sqrt(5))\n",
    "\n",
    "            ####################################################################################\n",
    "\n",
    "            n_query = x.size(1) - n_support\n",
    "            x = x.cuda()\n",
    "            x_var = Variable(x)\n",
    "\n",
    "            x_a_i = x_var[:,:n_support,:,:,:].contiguous().view( n_way* n_support, *x.size()[2:]) # (25 (5-way * 5-n_support), 3, 224, 224)\n",
    "            x_b_i = x_var[:,n_support:,:,:,:].contiguous().view( n_way* n_query,  *x.size()[2:]) # (75 (5-way * 15-n_qeury), 3, 224, 224)\n",
    "            y_a_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_support ) )).cuda() # (25,)\n",
    "            y_b_i = Variable( torch.from_numpy( np.repeat(range( n_way ), n_query ) )).cuda() # (75,)\n",
    "            y_b_i = y_b_i.detach().cpu().numpy()\n",
    "\n",
    "            ####################################################################################\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pretrained_model.eval()\n",
    "\n",
    "                nil_cls = torch.zeros([n_way, 512])\n",
    "                for i in range(n_way):\n",
    "                    cls_idx = y_a_i==i\n",
    "                    nil_cls[i] = torch.mean(pretrained_model.feature(x_a_i)[cls_idx].cpu(), dim=0)\n",
    "                wo_clas_scores = torch.mm(pretrained_model.feature(x_b_i).cpu(), nil_cls.T)\n",
    "\n",
    "                topk_scores, topk_labels = wo_clas_scores.data.topk(1, 1, True, True)\n",
    "                topk_ind = topk_labels.cpu().numpy()\n",
    "\n",
    "                top1_correct = np.sum(topk_ind[:,0] == y_b_i)\n",
    "                correct_this, count_this = float(top1_correct), len(y_b_i)\n",
    "                acc_lst.append(correct_this/count_this*100)\n",
    "                # print ('prt w/o clas {:2.4f}'.format(correct_this/count_this*100))\n",
    "        df['r{}'.format(r)] = acc_lst\n",
    "    df.to_csv('./delete_results/{}_zero_channel.csv'.format(dataset_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "model = 'ResNet10'\n",
    "method = 'baseline'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = 'miniImageNet'\n",
    "datamgr = miniImageNet_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "source_loader = datamgr.get_data_loader(aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_repr_all = []\n",
    "source_label_all = []\n",
    "\n",
    "for idx, (image, label) in enumerate(source_loader):\n",
    "    image = image.cuda()\n",
    "    block1_out, block2_out, block3_out, block4_out, last_out = pretrained_model.feature.return_features(image)\n",
    "#     last_out = pretrained_model(image)[:,:64]\n",
    "    \n",
    "    source_repr_all.append(last_out.cpu())\n",
    "    source_label_all.append(label)\n",
    "\n",
    "source_repr_all = torch.stack(source_repr_all).reshape(-1, source_repr_all[0].shape[-1])\n",
    "source_label_all = torch.stack(source_label_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = 'ChestX'\n",
    "\n",
    "if target_dataset == 'miniImageNet':\n",
    "    datamgr = miniImageNet_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "    target_loader = datamgr.get_data_loader(aug=False, train=False)\n",
    "elif target_dataset == 'CropDisease':\n",
    "    datamgr = CropDisease_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "    target_loader = datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'EuroSAT':\n",
    "    datamgr = EuroSAT_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "    target_loader = datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'ISIC':\n",
    "    datamgr = ISIC_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "    target_loader = datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'ChestX':\n",
    "    datamgr = Chest_few_shot.SimpleDataManager(image_size, batch_size = 32)\n",
    "    target_loader = datamgr.get_data_loader(aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_repr_all = []\n",
    "target_label_all = []\n",
    "\n",
    "for idx, (image, label) in enumerate(target_loader):\n",
    "    image = image.cuda()\n",
    "    block1_out, block2_out, block3_out, block4_out, last_out = pretrained_model.feature.return_features(image)\n",
    "#     last_out = pretrained_model(image)[:,:64]\n",
    "    \n",
    "    target_repr_all.append(last_out.cpu())\n",
    "    target_label_all.append(label)\n",
    "\n",
    "#\n",
    "target_repr_all = torch.stack(target_repr_all).reshape(-1, target_repr_all[0].shape[-1])\n",
    "target_label_all = torch.stack(target_label_all).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_repr(repr_all, label_all):\n",
    "    label_repr_dict = {}\n",
    "    for label in label_all.unique().tolist():\n",
    "        find_idx = label_all == label\n",
    "        label_repr_all = repr_all[find_idx]\n",
    "        label_repr_dict[label] = torch.mean(label_repr_all, dim=0)\n",
    "    return label_repr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_label_repr = make_label_repr(source_repr_all, source_label_all)\n",
    "# target_label_repr = make_label_repr(source_repr_all, source_label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mtx = np.zeros([len(source_label_repr.keys()), len(target_label_repr.keys())])\n",
    "\n",
    "for source_label, source_repr in source_label_repr.items():\n",
    "    for target_label, target_repr in target_label_repr.items():\n",
    "        distance_mtx[source_label, target_label] = torch.sum(source_repr*target_repr)/(torch.norm(source_repr)*torch.norm(target_repr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.pcolor(distance_mtx)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('./src/{}_miniimagenet_repr3_cosine.pdf'.format(method), bbox_inches='tight', format='pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "T = 5.0\n",
    "\n",
    "source_repr_all = target_repr_all\n",
    "source_label_all = target_label_all\n",
    "\n",
    "for curr_repr, curr_label in tqdm(list(zip(source_repr_all, source_label_all))):\n",
    "    xxx = torch.sum(torch.exp(-torch.norm(curr_repr - source_repr_all, dim=1)/T)) - 1\n",
    "    yyy = torch.sum(torch.exp(-torch.norm(curr_repr - source_repr_all[curr_label == source_label_all], dim=1)/T)) - 1\n",
    "    \n",
    "    if xxx < 1e-6:\n",
    "        xxx = 1e-6\n",
    "    if yyy < 1e-6:\n",
    "        yyy = 1e-6\n",
    "        \n",
    "    tot += -np.log(yyy/xxx)\n",
    "\n",
    "tot /= len(source_repr_all)\n",
    "print (tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "miniImageNet\n",
    "baseline repr3, repr4 (4.0569), logit (1.4584)\n",
    "baselinebody repr3, repr4 (0.6776), logit (2.2129)\n",
    "\n",
    "CropDisease\n",
    "baseline repr3, repr4 (), logit ()\n",
    "baselinebody repr3, repr4 (0.8321), logit ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(source_repr_all, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[5] > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
