{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import backbone\n",
    "from methods.baselinetrain import BaselineTrain\n",
    "from io_utils import parse_args, get_resume_file, get_best_file, get_assigned_file\n",
    "from datasets import miniImageNet_few_shot, ISIC_few_shot, EuroSAT_few_shot, CropDisease_few_shot, Chest_few_shot\n",
    "from data.datamgr import SimpleDataManager, SetDataManager\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "n_way = 5\n",
    "n_support = 5\n",
    "n_query = 15\n",
    "few_shot_params = dict(n_way=n_way, n_support=n_support)\n",
    "\n",
    "model = 'ResNet10'\n",
    "method = 'baseline'\n",
    "pretrained_dataset = 'miniImageNet'\n",
    "save_dir = './logs'\n",
    "\n",
    "source_datamgr = miniImageNet_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "source_loader = source_datamgr.get_data_loader(aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = 'ISIC'\n",
    "\n",
    "if target_dataset == 'miniImageNet':\n",
    "    target_datamgr = miniImageNet_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "    target_loader = target_datamgr.get_data_loader(aug=False, train=False)\n",
    "elif target_dataset == 'CropDisease':\n",
    "    target_datamgr = CropDisease_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "    target_loader = target_datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'EuroSAT':\n",
    "    target_datamgr = EuroSAT_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "    target_loader = target_datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'ISIC':\n",
    "    target_datamgr = ISIC_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "    target_loader = target_datamgr.get_data_loader(aug=False)\n",
    "elif target_dataset == 'ChestX':\n",
    "    target_datamgr = Chest_few_shot.SimpleDataManager(image_size, batch_size = 128)\n",
    "    target_loader = target_datamgr.get_data_loader(aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model, method, pretrained_dataset, save_dir, type_dir, dataset_name, epoch=999):\n",
    "    if pretrained_dataset == 'miniImageNet':\n",
    "        num_classes = 64\n",
    "    elif pretrained_dataset == 'tieredImageNet':\n",
    "        num_classes = 351\n",
    "    \n",
    "    model_dict = {model: backbone.ResNet10(method=method, track_bn=True, reinit_bn_stats=False)}\n",
    "    pretrained_model = BaselineTrain(model_dict[model], num_classes, loss_type='softmax')\n",
    "    \n",
    "    checkpoint_dir = '%s/checkpoints/%s/%s_%s/%s/' %(save_dir, pretrained_dataset, model, method, type_dir)\n",
    "    if 'type1' in type_dir:\n",
    "        modelfile = get_assigned_file(checkpoint_dir, epoch)\n",
    "    else:\n",
    "        modelfile = get_assigned_file(checkpoint_dir, epoch, dataset_name=dataset_name)\n",
    "    state = torch.load(modelfile)['state']\n",
    "\n",
    "    pretrained_model.load_state_dict(state, strict=True)\n",
    "    pretrained_model.cuda()\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    for p in pretrained_model.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repr_label(pretrained_model, loader):\n",
    "    pretrained_model.eval()\n",
    "    \n",
    "    repr_lst = []\n",
    "    label_lst = []\n",
    "\n",
    "    for idx, (image, label) in tqdm(enumerate(loader)):\n",
    "        image = image.cuda()\n",
    "        last_repr = pretrained_model.feature(image)\n",
    "\n",
    "        repr_lst.append(last_repr.cpu())\n",
    "        label_lst.append(label)\n",
    "    \n",
    "    return torch.cat(repr_lst, dim=0), torch.cat(label_lst, dim=0)\n",
    "\n",
    "def get_clustering_measure(features, target):\n",
    "    N = target.size(0)\n",
    "    C = len(target.unique())\n",
    "    \n",
    "    class_features = []\n",
    "    for c in range(C):\n",
    "        class_features.append(features[target==c])\n",
    "    \n",
    "    mu = torch.mean(features, dim=0)\n",
    "    class_mu = []\n",
    "    for c in range(C):\n",
    "        class_mu.append(torch.mean(class_features[c], dim=0))\n",
    "    \n",
    "    sigma_within = 0\n",
    "    sigma_btw = 0\n",
    "    \n",
    "    for c in range(C):\n",
    "        sigma_btw += torch.norm(class_mu[c]-mu)\n",
    "        for feature in class_features[c]:\n",
    "            sigma_within += torch.norm(feature-class_mu[c])\n",
    "    \n",
    "    sigma_within /= N\n",
    "    sigma_btw /= C\n",
    "    \n",
    "    return sigma_within.item(), sigma_btw.item(), (sigma_within/sigma_btw).item()\n",
    "\n",
    "def get_vmeasure(repr_np, label_np):\n",
    "    num_classes = len(np.unique(label_np))\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=0).fit(repr_np)\n",
    "    v_measure = v_measure_score(label_np, kmeans.labels_)\n",
    "    return v_measure*100\n",
    "\n",
    "def get_cos(out, y):\n",
    "    cos = torch.nn.CosineSimilarity()\n",
    "    cos_mtx = torch.zeros([len(out), len(out)])\n",
    "    for i in range(len(out)):\n",
    "        cos_mtx[i] = cos(out, out[i].view(1, -1))\n",
    "        \n",
    "    same_mtx = (y.view(1, -1) == y.view(-1, 1)).float().cpu()\n",
    "    diff_mtx = 1 - same_mtx\n",
    "    same_mtx[range(len(same_mtx)), range(len(same_mtx))] = 0.\n",
    "    \n",
    "    same_cos = cos_mtx * same_mtx\n",
    "    diff_cos = cos_mtx * diff_mtx\n",
    "    \n",
    "    return torch.sum(same_cos).item() / len(torch.where(same_cos!=0)[0]), torch.sum(diff_cos).item() / len(torch.where(diff_cos!=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dirs = ['type1_strong', 'type4_strong_gamma125', 'type4_strong_gamma250', 'type4_strong_gamma375', 'type4_strong_gamma500', 'type4_strong_gamma625', 'type4_strong_gamma750', 'type4_strong_gamma875', 'type3_strong']\n",
    "\n",
    "source_clustering_measure_lst = []\n",
    "target_clustering_measure_lst = []\n",
    "source_v_measure_lst = []\n",
    "target_v_measure_lst = []\n",
    "\n",
    "for type_dir in type_dirs:\n",
    "    pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir, type_dir, dataset_name=target_dataset)\n",
    "    \n",
    "    source_repr, source_label = get_repr_label(pretrained_model, source_loader)\n",
    "    source_repr_np, source_label_np = source_repr.numpy(), source_label.numpy()\n",
    "    \n",
    "    target_repr, target_label = get_repr_label(pretrained_model, target_loader)\n",
    "    target_repr_np, target_label_np = target_repr.numpy(), target_label.numpy()\n",
    "    \n",
    "    _, _, source_clustering_measure = get_clustering_measure(source_repr, source_label)\n",
    "    _, _, target_clustering_measure = get_clustering_measure(target_repr, target_label)\n",
    "    \n",
    "    source_clustering_measure_lst.append(source_clustering_measure)\n",
    "    target_clustering_measure_lst.append(target_clustering_measure)\n",
    "    \n",
    "    source_v_measure = get_vmeasure(source_repr_np, source_label_np)\n",
    "    target_v_measure = get_vmeasure(target_repr_np, target_label_np)\n",
    "    \n",
    "    source_v_measure_lst.append(source_v_measure)\n",
    "    target_v_measure_lst.append(target_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.round(source_clustering_measure_lst, 2))\n",
    "print (np.round(target_clustering_measure_lst, 2))\n",
    "print (np.round(source_v_measure_lst, 2))\n",
    "print (np.round(target_v_measure_lst, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dir = 'type4_strong_gamma500'\n",
    "\n",
    "source_clustering_measure_lst = []\n",
    "target_clustering_measure_lst = []\n",
    "source_v_measure_lst = []\n",
    "target_v_measure_lst = []\n",
    "\n",
    "for epoch in [100, 200, 300, 400, 500, 600, 700, 800, 900]:\n",
    "    pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir, type_dir, dataset_name=target_dataset, epoch=epoch)\n",
    "    \n",
    "    source_repr, source_label = get_repr_label(pretrained_model, source_loader)\n",
    "    source_repr_np, source_label_np = source_repr.numpy(), source_label.numpy()\n",
    "    \n",
    "    target_repr, target_label = get_repr_label(pretrained_model, target_loader)\n",
    "    target_repr_np, target_label_np = target_repr.numpy(), target_label.numpy()\n",
    "    \n",
    "    _, _, source_clustering_measure = get_clustering_measure(source_repr, source_label)\n",
    "    _, _, target_clustering_measure = get_clustering_measure(target_repr, target_label)\n",
    "    \n",
    "    source_clustering_measure_lst.append(source_clustering_measure)\n",
    "    target_clustering_measure_lst.append(target_clustering_measure)\n",
    "    \n",
    "    source_v_measure = get_vmeasure(source_repr_np, source_label_np)\n",
    "    target_v_measure = get_vmeasure(target_repr_np, target_label_np)\n",
    "    \n",
    "    source_v_measure_lst.append(source_v_measure)\n",
    "    target_v_measure_lst.append(target_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.round(source_clustering_measure_lst, 2))\n",
    "print (np.round(target_clustering_measure_lst, 2))\n",
    "print (np.round(source_v_measure_lst, 2))\n",
    "print (np.round(target_v_measure_lst, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsnecuda import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(repr_np, label_np):\n",
    "    tsne_model = TSNE(n_components=2, perplexity=50.0, n_iter=1000)\n",
    "    embedded_repr = tsne_model.fit_transform(repr_np)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(embedded_repr[:, 0], embedded_repr[:, 1], c=label_np, alpha=0.4, s=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    # plt.savefig('./src/{}_{}_test_vehicle.pdf'.format(alg, dataset), bbox_inches='tight', format='pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dir = 'type1_strong'\n",
    "# type_dir = 'type3_strong'\n",
    "# type_dir = 'type4_strong_gamma500'\n",
    "\n",
    "pretrained_model = get_pretrained_model(model, method, pretrained_dataset, save_dir, type_dir, dataset_name=target_dataset)\n",
    "pretrained_model.eval()\n",
    "\n",
    "source_repr, source_label = get_repr_label(source_loader)\n",
    "source_repr_np, source_label_np = source_repr.numpy(), source_label.numpy()\n",
    "plot_tsne(source_repr_np, source_label_np)\n",
    "\n",
    "target_repr, target_label = get_repr_label(target_loader)\n",
    "target_repr_np, target_label_np = target_repr.numpy(), target_label.numpy()\n",
    "plot_tsne(target_repr_np, target_label_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_v_measure = get_vmeasure(source_repr_np, source_label_np)\n",
    "target_v_measure = get_vmeasure(target_repr_np, target_label_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (source_v_measure, target_v_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
